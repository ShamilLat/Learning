HPL-ViT: A Unified Perception Framework for Heterogeneous Parallel LiDARs in V2V
https://arxiv.org/pdf/2309.15572.pdf

Authors: Yuhang Liu, Boyi Sun, Yuke Li, Yuzheng Hu, Fei-Yue Wang

Publication Date: September 27, 2023

The article "HPL-ViT: A Unified Perception Framework for Heterogeneous Parallel LiDARs in V2V" explores advanced methods in autonomous driving and LiDAR (Light Detection and Ranging) technologies. The authors introduce an innovative architecture, HPL-ViT (Heterogeneous Parallel LiDARs-Vision Transformer), designed for effective integration and analysis of data from heterogeneous LiDAR systems used in various vehicles. The primary goal is to enhance interaction and cooperative perception in the context of V2V (Vehicle-to-Vehicle) communications.

HPL-ViT employs graph-attentive and cross-attentive mechanisms to process data from LiDAR systems of different categories and operating frequencies. This allows for considering the diversity of characteristics of each LiDAR system and ensures efficient data merging for improved perception accuracy in dynamic and varied scenarios. Through experiments on the specially developed heterogeneous dataset OPV2V-HPL, HPL-ViT demonstrates superior results, significantly outperforming other methods in all test scenarios, and exhibits excellent generalizability.

The paper makes a significant contribution to the development of autonomous driving systems, presenting an innovative approach to processing and analyzing data from diverse sources within V2V networks.
