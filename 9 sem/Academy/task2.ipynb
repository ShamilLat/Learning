{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "2dfe5a88-b725-4319-826c-6b8028feca8c",
      "metadata": {
        "tags": [],
        "id": "2dfe5a88-b725-4319-826c-6b8028feca8c"
      },
      "source": [
        "# Глава I: экстрактивное аннотирование"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://drive.google.com/drive/folders/15lciCVCPwazFPle2g_jWx3GtwdJ_nTBR"
      ],
      "metadata": {
        "id": "zljUzT6Nu-sJ",
        "outputId": "62be69f6-5b29-4241-aa42-78cd0617622e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "zljUzT6Nu-sJ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-09-27 11:42:13--  https://drive.google.com/drive/folders/15lciCVCPwazFPle2g_jWx3GtwdJ_nTBR\n",
            "Resolving drive.google.com (drive.google.com)... 173.194.69.138, 173.194.69.113, 173.194.69.101, ...\n",
            "Connecting to drive.google.com (drive.google.com)|173.194.69.138|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘15lciCVCPwazFPle2g_jWx3GtwdJ_nTBR.1’\n",
            "\n",
            "15lciCVCPwazFPle2g_     [ <=>                ] 267.88K  --.-KB/s    in 0.1s    \n",
            "\n",
            "2023-09-27 11:42:13 (2.01 MB/s) - ‘15lciCVCPwazFPle2g_jWx3GtwdJ_nTBR.1’ saved [274313]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets\n",
        "!pip install transformers\n",
        "!pip install sentence_transformers\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kpRpRKnPc7VK",
        "outputId": "f39e722a-0cd1-4ff3-d101-26fa80fa5466"
      },
      "id": "kpRpRKnPc7VK",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.14.5)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.23.5)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.3.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.15)\n",
            "Requirement already satisfied: fsspec[http]<2023.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.8.5)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.17.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (3.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (4.5.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2023.7.22)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.3.post1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.33.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.17.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.3.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n",
            "Requirement already satisfied: sentence_transformers in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (4.33.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (4.66.1)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (2.0.1+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (0.15.2+cu118)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.23.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.11.2)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (3.8.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (0.1.99)\n",
            "Requirement already satisfied: huggingface-hub>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (0.17.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (3.12.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (2.31.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (4.5.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (23.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence_transformers) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence_transformers) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence_transformers) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence_transformers) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->sentence_transformers) (3.27.4.1)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->sentence_transformers) (16.0.6)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (2023.6.3)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (0.13.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (0.3.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->sentence_transformers) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->sentence_transformers) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers) (3.2.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->sentence_transformers) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6.0->sentence_transformers) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (2023.7.22)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->sentence_transformers) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0n6DTAtTdNYs",
        "outputId": "7216f73e-c4c7-4396-e6d4-896449231434"
      },
      "id": "0n6DTAtTdNYs",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c6132b65-cfed-43a9-a2bd-6a7a35a0e8fc",
      "metadata": {
        "id": "c6132b65-cfed-43a9-a2bd-6a7a35a0e8fc"
      },
      "source": [
        "## Загружаем данные"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c37b540e-9e16-4002-a971-89f0583d7412",
      "metadata": {
        "id": "c37b540e-9e16-4002-a971-89f0583d7412"
      },
      "source": [
        "Библиотека **Hugging Face Datasets** предназначена для легкой загрузки и обработки данных (в т.ч. есть встроенная поддержка параллельной обработки записей). Поддерживаются все типы данных и большинство современных форматов. Основная филосифия - эффективность работы, поэтому перед работой с данными они кэшируется в бинарном виде для последующей ленивой загрузки батчами в асинхронном режиме."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5cddebe9-ef0f-4bc8-a306-d6022e79d8ea",
      "metadata": {
        "id": "5cddebe9-ef0f-4bc8-a306-d6022e79d8ea"
      },
      "outputs": [],
      "source": [
        "import datasets\n",
        "from pathlib import Path\n",
        "import random\n",
        "\n",
        "# ПОМЕНЯТЬ ЗДЕСЬ ПУТЬ ДЛЯ ЗАГРУЗКИ С ГУГЛ ДИСКА\n",
        "PROJECT_DATA_DIR=Path(\"drive/MyDrive/Academy\")\n",
        "\n",
        "DATA_DIR = PROJECT_DATA_DIR / \"data\"\n",
        "\n",
        "CACHE_DIR = Path(\"./cache\")\n",
        "\n",
        "data_name = \"ru_news\"  # \"news_and_summaries\"\n",
        "data = datasets.load_dataset(\"json\", data_files={f\"{split}\": (\n",
        "    DATA_DIR / f\"{data_name}.{split}\").as_posix() for split in [\"train\", \"test\"]}, cache_dir=CACHE_DIR.as_posix())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e62227d1-4597-457e-91e4-434c0f262037",
      "metadata": {
        "id": "e62227d1-4597-457e-91e4-434c0f262037"
      },
      "source": [
        "Данные разбиты на обучающую **(train)** и тестовую **(test)** подвыборки\n",
        "\n",
        "Каждый пример состоит из:\n",
        "* документа **(document)** разбитого на предложения\n",
        "* списка наиболее репрезентативных предложений **(most_important_sentences)**\n",
        "* номера кластера **(cluster_id)**\n",
        "* аннотации **(cluster_summary)**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9c8997ab-b953-4756-9b3c-d57efef02e06",
      "metadata": {
        "id": "9c8997ab-b953-4756-9b3c-d57efef02e06"
      },
      "source": [
        "Рассмотрим пример:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "412edccd-3d64-4a92-81e8-077bd3cfeab9",
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "412edccd-3d64-4a92-81e8-077bd3cfeab9",
        "outputId": "db3d73be-21a2-4563-9b9e-ae6cfb8f85f6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'document': ['Грузовой самолет Boeing 737 упал в воду у побережья Гонолулу 2 июля.',\n",
              "  'Как передает американский телеканал CNBC, причиной ЧП стала неисправность двигателя.',\n",
              "  'По его данным, вскоре после взлета у самолета начались технические неполадки.',\n",
              "  'Он развернулся, чтобы возвратиться в аэропорт в Гонолулу, но не долетел.',\n",
              "  'На борту находились два пилота – им пришлось произвести экстренную посадку воздушного судна на воду.',\n",
              "  '«В полете сообщалось о выходе из строя двигателя №1 и затруднениях с поддержанием высоты.',\n",
              "  'Из-за невозможности увидеть аэропорт экипажу были даны указания.',\n",
              "  'После того, как поступило предупреждение о малой высоте полета, диспетчер предложил направиться в аэропорт Калаэлоа, который находился ближе.',\n",
              "  'Самолет не смог добраться до аэропорта», - передает портал aviation-safety.net.',\n",
              "  'Оба находившихся в самолете пилота спасены.',\n",
              "  'Одного из них госпитализировали, сообщили в министерстве транспорта США.',\n",
              "  'В свою очередь, в Федеральном управлении гражданской авиации США указали, что обоих пилотов спасла береговая охрана.',\n",
              "  'Проводится расследование причин произошедшего.',\n",
              "  'Известно, что борт принадлежит авиакомпании Transair, с самолетом которой шесть лет назад – 29 июня 2015 года – также произошел инцидент на Гавайях.',\n",
              "  'Тогда борт Shorts 360 получил значительные повреждения после жесткой посадки в аэропорту Калаэлоа.',\n",
              "  'Оба его пилота не пострадали.',\n",
              "  'Ранее в пятницу сообщалось о неполадках, произошедших на борту грузового Boeing авиакомпании «Атран».',\n",
              "  'Самолет вылетел из Красноярска в китайский город Гуанчжоу, но был вынужден вернуться в аэропорт вылета.',\n",
              "  'По предварительной информации, произошла утечка топлива.',\n",
              "  'Посадка в Красноярске прошла штатно.',\n",
              "  'Причина ЧП устанавливается, передает ТАСС.',\n",
              "  'Самолет около часа кружил около города, вырабатывая топливо.',\n",
              "  'По факту возвращения самолета в аэропорт началась доследственная проверка, сообщили в Западно-Сибирском следственном управлении на транспорте СК РФ.'],\n",
              " 'most_important_sentences': [17, 19, 2, 0, 16, 10, 1, 8, 12, 15, 4],\n",
              " 'cluster_id': 5861,\n",
              " 'cluster_summary': 'Неисправность двигателя привела к тому, что пилотам грузового борта Boeing 737 пришлось сажать самолет на воду вскоре после взлета из аэропорта Гонолулу. Оба члена экипажа выжили, один из них находится в больнице. Власти начали расследование инцидента, ставшего вторым в эту пятницу с участием грузового самолета Boeing - еще одно ЧП случилось в Красноярске, где пилотам пришлось возвращаться в аэропорт вылета. Посадка там прошла штатно.'}"
            ]
          },
          "metadata": {},
          "execution_count": 119
        }
      ],
      "source": [
        "data['train'][0]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d2151f18-1e40-4dd9-ad6b-c6dad1bc5d4f",
      "metadata": {
        "id": "d2151f18-1e40-4dd9-ad6b-c6dad1bc5d4f"
      },
      "source": [
        "## Часть 1: позиционный бейслайн"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "999b6760-3002-4853-8736-c10308fc7b4e",
      "metadata": {
        "id": "999b6760-3002-4853-8736-c10308fc7b4e"
      },
      "source": [
        "### Задание 1.1: визуализировать most_important_sentences"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2873290d-9721-4042-bf84-fde07d1c7798",
      "metadata": {
        "id": "2873290d-9721-4042-bf84-fde07d1c7798"
      },
      "source": [
        "Экстрактивное аннотирование - задача классификация фрагментов текста. В данном случае классифицируем предложения по принципу важное/неважное. Обычно такой разметки нет и приходится обходиться различными эвристиками, но, к счастью, в наших данных есть пользовательская разметка **most_important_sentences**.\n",
        "\n",
        "Давайте попробуем построить гистограмму"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8087b5e3-30a1-4843-9346-08bf99b3eab8",
      "metadata": {
        "id": "8087b5e3-30a1-4843-9346-08bf99b3eab8"
      },
      "outputs": [],
      "source": [
        "from matplotlib import pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6559d55f-c777-4810-974b-902d4c93f5fb",
      "metadata": {
        "id": "6559d55f-c777-4810-974b-902d4c93f5fb"
      },
      "outputs": [],
      "source": [
        "def convert_split_labels_to_list_of_positions(split):\n",
        "    res = []\n",
        "\n",
        "    for label in split:\n",
        "      res.extend(label[\"most_important_sentences\"])\n",
        "\n",
        "    return res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ec0eb689-520f-4467-aa6c-45fd19a53f93",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 534
        },
        "id": "ec0eb689-520f-4467-aa6c-45fd19a53f93",
        "outputId": "0a9295f8-b88d-45de-9de9-4e64679d0f11"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([962., 609., 477., 447., 379., 333., 320., 266., 241., 210., 171.,\n",
              "        157., 128.,  97.,  83.,  54.,  44.,  12.,  15.,   7.]),\n",
              " array([ 0.  ,  1.95,  3.9 ,  5.85,  7.8 ,  9.75, 11.7 , 13.65, 15.6 ,\n",
              "        17.55, 19.5 , 21.45, 23.4 , 25.35, 27.3 , 29.25, 31.2 , 33.15,\n",
              "        35.1 , 37.05, 39.  ]),\n",
              " <BarContainer object of 20 artists>)"
            ]
          },
          "metadata": {},
          "execution_count": 122
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "important_sentence_positions = convert_split_labels_to_list_of_positions(\n",
        "    data[\"train\"])\n",
        "plt.hist(important_sentence_positions, bins=20)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a601e1ba-191e-4920-bf05-b6435e9ca1b9",
      "metadata": {
        "id": "a601e1ba-191e-4920-bf05-b6435e9ca1b9"
      },
      "source": [
        "### Задание 1.2: на основе гистогаммы выше придумайте позиционную стратегию выбора предложений"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bfab089e-0f02-4af1-a8a8-c9ee9204f720",
      "metadata": {
        "id": "bfab089e-0f02-4af1-a8a8-c9ee9204f720"
      },
      "source": [
        "*Hint:* попробуйте с нормализацией по длине документа (в предложениях) и без"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d6724719-4c55-4b02-b80f-a374d96ffa35",
      "metadata": {
        "id": "d6724719-4c55-4b02-b80f-a374d96ffa35"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "def positional_baseline(example, **kwargs):\n",
        "    important_positions = []\n",
        "\n",
        "    # Получаем длины предложений\n",
        "    sentence_lengths = [len(sentence.split()) for sentence in example['document']]\n",
        "\n",
        "    # Нормализация по длине документа\n",
        "    normalized_lengths = [length / sum(sentence_lengths) for length in sentence_lengths]\n",
        "\n",
        "    # Выбираем позиции на основе нормализованных длин\n",
        "    threshold = 0.045  # Порог для определения важных предложений\n",
        "    for i, length in enumerate(normalized_lengths):\n",
        "        if length > threshold:\n",
        "            important_positions.append(i)\n",
        "\n",
        "    return important_positions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "699a7480-c100-4629-8093-96e824703cf9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "699a7480-c100-4629-8093-96e824703cf9",
        "outputId": "b98be520-2de6-4581-aac2-2ab3b5b16792"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "***ТЕКСТ СТАТЬИ:***\n",
            "\n",
            "В Туве, Ингушетии и Кабардино-Балкарии по итогам 2020 года зафиксирован наибольший уровень бедности населения. Об этом сообщил замдиректора департамента информационных технологий Минтруда Андрей Лебедев, ссылаясь на данные Росстата, передает ТАСС. Уровень бедности высчитывается как доля населения с доходами ниже прожиточного минимума к общему числу граждан, проживающих в регионе. В Туве таких жителей 34,1%. В Ингушетии, расположившейся на втором месте, их 30%. Третья позиция антирейтинга у Кабардино-Балкарии — там уровень бедности составляет 24,2%. Кроме того, относительно высокий уровень бедности Росстат зарегистрировал в Республике Алтай — более 23%. Меньше всего доля бедного населения (от 5% до 10%) в Москве, Санкт-Петербурге, Подмосковье, Калужской, Ленинградской, Нижегородской, Курской, Белгородской, Воронежской, Свердловской, Ярославской, Магаданской и Сахалинской областях, Татарстане, Ямало-Ненецком, Ханты-Мансийском и Чукотском автономном округах. Лебедев заявил, что наибольшей проблемой в борьбе с низкими доходами населения является так называемая якорная бедность. «Когда семья глубоко бедная находится глубоко в такой стадии, она не может вырваться, дети не могут получить соответствующее образование, все это замкнутый круг», — пояснил представитель Минтруда. Выходом из подобной ситуации, по мнению чиновника, является построение в регионе экономической политики, когда молодые специалисты могут максимально эффективно применять свои навыки при трудоустройстве. Второй необходимый фактор — социальный контракт. Согласно данным Росстата на 6 августа, в стране насчитывалось 17,7 млн человек, живущих за чертой бедности — это 12,1% от населения. Этот показатель снижается с 2015 года, в 2019 году в стране проживали 18,1 млн бедных россиян. Снижение их числа Росстат связывал в том числе с веерными социальными выплатами, которые власти устанавливали в период пандемии коронавирусной инфекции. Средний прожиточный минимум в России сейчас составляет 11,6 тыс. руб. (12,7 тыс. для трудоспособных граждан, 11,3 тыс. для детей, 10 тыс. для пенсионеров). Данные Росстата, озвученные Лебедевым 24 августа, практически полностью повторяют результаты июньского исследования « РИА Рейтинг». В нем также самый высокий уровень бедности фиксировался в Туве, Ингушетии и Кабардино-Балкарии, процентные показатели отличались на десятые доли. В десятку субъектов с наибольшей долей бедного населения также входили Республика Алтай, Еврейская автономная область, Калмыкия, Карачаево-Черкессия, Забайкалье, Чечня и Марий Эл. В начале августа президент Владимир Путин поручил правительству организовать каждые полгода мониторинг средств у граждан с низкими доходами. В июле глава государства назвал бедность одной из главных проблем страны. Глава Счетной палаты Алексей Кудрин в интервью РБК говорил , что ценой в несколько сотен миллиардов рублей в год можно создать модель, позволяющую снизить бедность в России вдвое. Для этого нужно регулярно проводить оценку нуждаемости семей и ранжировать им адресную финансовую помощь в зависимости от материального положения. Власти планируют в два раза сократить число бедных к 2030 году.\n",
            "\n",
            "***ТЕКСТ ПРЕДСКАЗАННОЙ АННОТАЦИИ:***\n",
            "\n",
            "Меньше всего доля бедного населения (от 5% до 10%) в Москве, Санкт-Петербурге, Подмосковье, Калужской, Ленинградской, Нижегородской, Курской, Белгородской, Воронежской, Свердловской, Ярославской, Магаданской и Сахалинской областях, Татарстане, Ямало-Ненецком, Ханты-Мансийском и Чукотском автономном округах. «Когда семья глубоко бедная находится глубоко в такой стадии, она не может вырваться, дети не могут получить соответствующее образование, все это замкнутый круг», — пояснил представитель Минтруда. Выходом из подобной ситуации, по мнению чиновника, является построение в регионе экономической политики, когда молодые специалисты могут максимально эффективно применять свои навыки при трудоустройстве. Согласно данным Росстата на 6 августа, в стране насчитывалось 17,7 млн человек, живущих за чертой бедности — это 12,1% от населения. Снижение их числа Росстат связывал в том числе с веерными социальными выплатами, которые власти устанавливали в период пандемии коронавирусной инфекции. Средний прожиточный минимум в России сейчас составляет 11,6 тыс. руб. (12,7 тыс. для трудоспособных граждан, 11,3 тыс. для детей, 10 тыс. для пенсионеров). В нем также самый высокий уровень бедности фиксировался в Туве, Ингушетии и Кабардино-Балкарии, процентные показатели отличались на десятые доли. В десятку субъектов с наибольшей долей бедного населения также входили Республика Алтай, Еврейская автономная область, Калмыкия, Карачаево-Черкессия, Забайкалье, Чечня и Марий Эл. Глава Счетной палаты Алексей Кудрин в интервью РБК говорил , что ценой в несколько сотен миллиардов рублей в год можно создать модель, позволяющую снизить бедность в России вдвое. Для этого нужно регулярно проводить оценку нуждаемости семей и ранжировать им адресную финансовую помощь в зависимости от материального положения.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "example_id = random.randint(0, len(data['train']))\n",
        "example = data['train'][example_id]\n",
        "\n",
        "extractive_prediction = positional_baseline(example)\n",
        "\n",
        "document_text = \" \".join(example['document'])\n",
        "summary = \" \".join(example['document'][sent_id]\n",
        "                   for sent_id in extractive_prediction)\n",
        "print(\"***ТЕКСТ СТАТЬИ:***\", f\"{document_text}\\n\", sep='\\n\\n')\n",
        "print(\"***ТЕКСТ ПРЕДСКАЗАННОЙ АННОТАЦИИ:***\", f\"{summary}\\n\", sep='\\n\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "94ad7a98-3454-4d12-8874-b140f2acd0df",
      "metadata": {
        "id": "94ad7a98-3454-4d12-8874-b140f2acd0df"
      },
      "source": [
        "## Часть 2: TF-IDF + MMR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ad1a247a-0dde-49f4-917a-4a5e79abd2a7",
      "metadata": {
        "id": "ad1a247a-0dde-49f4-917a-4a5e79abd2a7"
      },
      "outputs": [],
      "source": [
        "# \"eng-com_web-public_2018_1M-words.txt\"\n",
        "CORP_NAME = \"rus-ru_web-public_2019_1M-words.txt\"\n",
        "\n",
        "\n",
        "def read_word_corpora():\n",
        "    with open(DATA_DIR / CORP_NAME) as f:\n",
        "        return dict((pair[0], int(pair[1])) for l in f if (pair := l.strip().split('\\t')[1:]))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b5b5e6e6-bec7-4db9-8d0c-2a3a39e2a1ae",
      "metadata": {
        "id": "b5b5e6e6-bec7-4db9-8d0c-2a3a39e2a1ae"
      },
      "source": [
        "### Задание 2.1: частотная векторизация TF-IDF"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ae897067-4f59-45d7-8ee6-b90ba900f2c3",
      "metadata": {
        "id": "ae897067-4f59-45d7-8ee6-b90ba900f2c3"
      },
      "source": [
        "Самый простой способ векторизации текста - составить вектор частот употребления его слов. Но вот незадача: по закону ципфа самые частотные слова это частицы, союзы или местоимения, то есть неинформативные служебные слова! Можно выбросить служебные слова, но что делать с частотными терминами, которые также не несут смысла, например \"мужщина\" и \"женщина\"?\n",
        "\n",
        "Решение - формула нормализации частот **TF-IDF**:\n",
        "$$\\text{TF-IDF}(w_i, document_k)=\\text{TF}(w_i, doc_k)\\cdot \\text{IDF}(w_i,DOCS)$$\n",
        "\n",
        "$TF$ - частота термина:\n",
        "$$\\text{TF}(w_i, doc_k)=\\text{frequency}(w_i, doc_k)$$\n",
        "\n",
        "$IDF$ - обратная частота встречаемости термина в документах, нормировачный коэффициент:\n",
        "$$\\text{IDF}(w_i,DOCS)=\\log{\\frac{|DOCS|}{|\\{doc_j \\in DOCS : w_i \\in doc_j \\}|+1}}$$"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3aa2b026-a88d-48df-b5f3-1c0d85c124e2",
      "metadata": {
        "id": "3aa2b026-a88d-48df-b5f3-1c0d85c124e2"
      },
      "source": [
        "Вам дан словарь документных частот **raw_word_df**. Напишите функцию вычисления TF-IDF."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "60b82efb-51d8-4ff0-84e0-4fbbdc68164e",
      "metadata": {
        "id": "60b82efb-51d8-4ff0-84e0-4fbbdc68164e"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "def simple_tokenize(text):\n",
        "    tokens = text.split()\n",
        "    return tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "75dd9eda-113f-4ebe-826d-48b62d421be3",
      "metadata": {
        "id": "75dd9eda-113f-4ebe-826d-48b62d421be3"
      },
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class TfIdfVectorizer:\n",
        "    def __init__(self, df_dict=None, tokenizer=simple_tokenize):\n",
        "        if df_dict is None:\n",
        "            df_dict = read_word_corpora()\n",
        "        self.df_dict = df_dict\n",
        "        self.tokenizer = tokenizer\n",
        "        self.df_idx_dict = {word: idx for idx,\n",
        "                            word in enumerate(df_dict.keys())}\n",
        "\n",
        "    def tf_idf_word(self, word, word_count):\n",
        "        tfidf = word_count * np.log(max(self.df_dict.values()) / (self.df_dict[word] + 1))\n",
        "        return tfidf\n",
        "\n",
        "    def tf_idf_text(self, text):\n",
        "        # default vector\n",
        "        tfidf_vector = np.zeros(len(self.df_idx_dict))\n",
        "\n",
        "        # words_and_counts=[(\"\",0)]\n",
        "        \"\"\"\"\"\"\n",
        "        words_and_counts = Counter(self.tokenizer(text))\n",
        "        words_and_counts = list(words_and_counts.items())\n",
        "\n",
        "        # Tokenize and count freqs\n",
        "\n",
        "        for word, count in words_and_counts:\n",
        "            if word in self.df_idx_dict:\n",
        "                tfidf_vector[self.df_idx_dict[word]\n",
        "                             ] = self.tf_idf_word(word, count)\n",
        "        return tfidf_vector\n",
        "\n",
        "    def __call__(self, text):\n",
        "        return self.tf_idf_text(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "abf5f423-564a-40da-9ad3-0e32bf321473",
      "metadata": {
        "scrolled": true,
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "abf5f423-564a-40da-9ad3-0e32bf321473",
        "outputId": "87a937c4-5e97-49ad-bf6c-1fcaa366bb01"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Вектор:\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            "Плотность:\n",
            " 0.00013%\n",
            "Уникальные значения:\n",
            " [-8.10877763e-07  0.00000000e+00  2.68231133e+00  2.93036275e+00\n",
            "  3.35663468e+00  3.43901836e+00  3.61138509e+00  3.69240007e+00\n",
            "  3.80933466e+00  3.93680056e+00  4.02785151e+00  4.05493693e+00\n",
            "  4.06098888e+00  4.17786061e+00  4.18454711e+00  4.18518626e+00\n",
            "  4.23561344e+00  4.28612255e+00  4.35101083e+00  4.42438859e+00\n",
            "  4.46355339e+00  4.61489188e+00  4.68018944e+00  4.84495772e+00\n",
            "  4.85928223e+00  4.89082523e+00  4.92775250e+00  4.96504940e+00\n",
            "  5.16592672e+00  5.21558386e+00  5.26453826e+00  5.38821824e+00\n",
            "  5.43492978e+00  5.47336028e+00  5.53142828e+00  5.62045195e+00\n",
            "  5.68732085e+00  5.71448721e+00  5.81911035e+00  5.92741754e+00\n",
            "  5.92772181e+00  5.93290871e+00  5.93812264e+00  6.03668539e+00\n",
            "  6.03711673e+00  6.04273177e+00  6.07838918e+00  6.08884542e+00\n",
            "  6.15651122e+00  6.15765954e+00  6.16921591e+00  6.19790721e+00\n",
            "  6.24235150e+00  6.25873121e+00  6.26438958e+00  6.26980930e+00\n",
            "  6.29585244e+00  6.32666532e+00  6.37927229e+00  6.42524615e+00\n",
            "  6.46872014e+00  6.49413178e+00  6.52794089e+00  6.56350772e+00\n",
            "  6.56465781e+00  6.59030024e+00  6.63929703e+00  6.64240166e+00\n",
            "  6.64302375e+00  6.68236892e+00  6.68366426e+00  6.68561042e+00\n",
            "  6.71059528e+00  6.73827170e+00  6.76955684e+00  6.80185243e+00\n",
            "  6.84431691e+00  6.92100402e+00  6.93507128e+00  6.97763089e+00\n",
            "  6.98724215e+00  6.99429064e+00  7.00406415e+00  7.04693437e+00\n",
            "  7.05254186e+00  7.06860267e+00  7.07510767e+00  7.07529166e+00\n",
            "  7.08395806e+00  7.10447661e+00  7.14142157e+00  7.19211638e+00\n",
            "  7.20186199e+00  7.22832439e+00  7.25780499e+00  7.25895640e+00\n",
            "  7.30734342e+00  7.33803950e+00  7.35819132e+00  7.36713707e+00\n",
            "  7.44589690e+00  7.45426515e+00  7.50747684e+00  7.51488977e+00\n",
            "  7.53290828e+00  7.64842116e+00  7.65820579e+00  7.66557424e+00\n",
            "  7.73357897e+00  7.75038609e+00  7.79073739e+00  7.80455794e+00\n",
            "  7.84099922e+00  7.84306321e+00  7.85344752e+00  7.85973026e+00\n",
            "  7.86816913e+00  7.93157834e+00  7.93383823e+00  7.94292920e+00\n",
            "  7.95441038e+00  7.97305894e+00  7.99928214e+00  8.03368357e+00\n",
            "  8.03869611e+00  8.07190478e+00  8.07711312e+00  8.17007619e+00\n",
            "  8.21400712e+00  8.26624634e+00  8.29830036e+00  8.31141531e+00\n",
            "  8.34156835e+00  8.35872142e+00  8.40474725e+00  8.40837701e+00\n",
            "  8.41202001e+00  8.41567632e+00  8.41934605e+00  8.43043673e+00\n",
            "  8.51171937e+00  8.52797989e+00  8.53525024e+00  8.53621039e+00\n",
            "  8.56556260e+00  8.65917210e+00  8.72184320e+00  8.76245792e+00\n",
            "  8.78497103e+00  8.83776231e+00  8.89524940e+00  8.97529211e+00\n",
            "  9.00786828e+00  9.09307574e+00  9.15761366e+00  9.16533571e+00\n",
            "  9.18886621e+00  9.19683438e+00  9.21296376e+00  9.24602462e+00\n",
            "  9.26297418e+00  9.28894966e+00  9.29776029e+00  9.32466775e+00\n",
            "  9.33380023e+00  9.35231928e+00  9.37118776e+00  9.43002826e+00\n",
            "  9.44018063e+00  9.45043713e+00  9.53651174e+00  9.54781130e+00\n",
            "  9.69441477e+00  9.73468867e+00  9.73958410e+00  9.76246824e+00\n",
            "  9.79104161e+00  9.83549337e+00  9.85076084e+00  9.91758718e+00\n",
            "  9.96470510e+00  9.98209684e+00  1.00739044e+01  1.01750005e+01\n",
            "  1.01965067e+01  1.02184856e+01  1.02639480e+01  1.03615865e+01\n",
            "  1.03875620e+01  1.04698001e+01  1.05594122e+01  1.05911609e+01\n",
            "  1.06239507e+01  1.06578523e+01  1.06929436e+01  1.07293112e+01\n",
            "  1.08062723e+01  1.08896539e+01  1.10807091e+01  1.11347764e+01\n",
            "  1.11919348e+01  1.13170979e+01  1.14601988e+01  1.16272528e+01\n",
            "  1.17225630e+01  1.18279235e+01  1.19457066e+01  1.20792380e+01\n",
            "  1.22333886e+01  1.24157102e+01  1.26388538e+01  1.29265358e+01\n",
            "  1.29280530e+01  1.29500255e+01  1.30404121e+01  1.31165796e+01\n",
            "  1.33320009e+01  1.50061106e+01  1.50688492e+01  1.53207947e+01\n",
            "  1.83409963e+01  1.90506769e+01  1.91184800e+01  1.91649937e+01\n",
            "  2.01866450e+01  2.03500010e+01  2.05278960e+01  2.07751239e+01\n",
            "  2.08832583e+01  2.09453707e+01  2.16824490e+01  2.27721816e+01\n",
            "  2.54601352e+01  2.57230675e+01  2.71208263e+01  5.77105732e+01]\n"
          ]
        }
      ],
      "source": [
        "raw_word_df = read_word_corpora()\n",
        "\n",
        "vectorizer = TfIdfVectorizer(df_dict=raw_word_df)\n",
        "\n",
        "test_vector = vectorizer(document_text)\n",
        "print(\"Вектор:\\n\", test_vector)\n",
        "print(\"Плотность:\\n {:.5%}\".format(\n",
        "    len(test_vector.nonzero())/test_vector.shape[-1]))\n",
        "print(\"Уникальные значения:\\n\", np.unique(test_vector))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1419a71b-834d-415f-8319-7195fc427752",
      "metadata": {
        "id": "1419a71b-834d-415f-8319-7195fc427752"
      },
      "source": [
        "### Задание 2.2: Оценка важности предложений по TF-IDF"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "10bb65c5-20af-4425-8f03-132a3fc70a08",
      "metadata": {
        "id": "10bb65c5-20af-4425-8f03-132a3fc70a08"
      },
      "source": [
        "В основе TF-IDF лежит идея, что частотные слова будут штрафоваться, а редкие термины, наоборот, получат максимальный вес. С другой стороны, важные предложения текста скорее всего будут богаты сущностями и ключевыми словами, а они в силу своей природы часто лежат в хвосте распределения частот слов языка, то есть имеют максимальные коэффициент IDF. Тогда можно оценить важность предложения как сумму TF-IDF его слов."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b540a9c3-356a-4385-ad2e-3b9f75b7959b",
      "metadata": {
        "id": "b540a9c3-356a-4385-ad2e-3b9f75b7959b"
      },
      "outputs": [],
      "source": [
        "def tfidf_sum(sentence_embeddings: np.ndarray, topk: int = None):\n",
        "    ranking = []\n",
        "\n",
        "    for i, sentence_embedding in enumerate(sentence_embeddings):\n",
        "        tfidf_score = np.sum(sentence_embedding)\n",
        "        ranking.append((i, tfidf_score))\n",
        "\n",
        "    ranking = sorted(ranking, key=lambda x: x[1], reverse=True)\n",
        "    ranking = [idx for idx, _ in ranking]\n",
        "\n",
        "    return ranking[:topk]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2ca5f1df-cf35-431f-b47b-1825de57d452",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ca5f1df-cf35-431f-b47b-1825de57d452",
        "outputId": "93d4ef40-cbca-46f6-b441-9b0e487e7691"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "***ТЕКСТ ПРЕДСКАЗАННОЙ АННОТАЦИИ:***\n",
            "\n",
            "Выходом из подобной ситуации, по мнению чиновника, является построение в регионе экономической политики, когда молодые специалисты могут максимально эффективно применять свои навыки при трудоустройстве. Средний прожиточный минимум в России сейчас составляет 11,6 тыс. руб. (12,7 тыс. для трудоспособных граждан, 11,3 тыс. для детей, 10 тыс. для пенсионеров). Глава Счетной палаты Алексей Кудрин в интервью РБК говорил , что ценой в несколько сотен миллиардов рублей в год можно создать модель, позволяющую снизить бедность в России вдвое.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "sent_embs = np.stack([vectorizer(sent) for sent in example['document']])\n",
        "\n",
        "extractive_prediction = tfidf_sum(sentence_embeddings=sent_embs, topk=3)\n",
        "\n",
        "# Нужно для связности аннотации\n",
        "# extractive_prediction = [idx for idx, _ in extractive_prediction]\n",
        "extractive_prediction = sorted(extractive_prediction)\n",
        "\n",
        "summary = \" \".join(example['document'][sent_id]\n",
        "                   for sent_id in extractive_prediction)\n",
        "print(\"***ТЕКСТ ПРЕДСКАЗАННОЙ АННОТАЦИИ:***\", f\"{summary}\\n\", sep='\\n\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4f7580b1-39d0-40cf-9cd4-6c5971ae6032",
      "metadata": {
        "id": "4f7580b1-39d0-40cf-9cd4-6c5971ae6032"
      },
      "source": [
        "### Задание 2.3: оптимизация TF-IDF"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4eacd803-3bdf-4f4e-8a88-1e1288cdc3c8",
      "metadata": {
        "id": "4eacd803-3bdf-4f4e-8a88-1e1288cdc3c8"
      },
      "source": [
        "Выше приведена классическая реализация TF-IDF. В ней проссматриваются 3 основных проблемы:\n",
        "* неизвестные слова игнорируются/переоцениваются\n",
        "* теряется связь между однокоренными словами\n",
        "* выходной вектор **крайне** разреженный\n",
        "\n",
        "**Решение**: предобработка и нормализация. В современном мире это делается статистическими токенизаторами на основе алгоритмов WordPiece/SentencePiece или BPE.\n",
        "\n",
        "Токенизатор для нормализации уже выбран за Вас.\n",
        "\n",
        "Вам необходимо применить его к словарю и придумать функцию предобработки строк для минимизации размера нового словаря частот."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "33f75186-c1ee-4f31-8851-b935769cb4d7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "33f75186-c1ee-4f31-8851-b935769cb4d7",
        "outputId": "839cbe85-6c18-4d93-8e64-76d66edbf8e7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Ло', '##жка']"
            ]
          },
          "metadata": {},
          "execution_count": 131
        }
      ],
      "source": [
        "from transformers import BertTokenizerFast, AutoTokenizer\n",
        "\n",
        "ENCODER_MODEL_PATH =  PROJECT_DATA_DIR / \"models/rubert-tiny2/\"\n",
        "\n",
        "bpe_tokenizer = AutoTokenizer.from_pretrained(ENCODER_MODEL_PATH)\n",
        "\n",
        "bpe_tokenizer.tokenize(\"Ложка\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "349f8d84-5984-4ad3-a400-13ea1a1a7542",
      "metadata": {
        "id": "349f8d84-5984-4ad3-a400-13ea1a1a7542"
      },
      "outputs": [],
      "source": [
        "from typing import List, Set, Dict\n",
        "from collections import defaultdict\n",
        "\n",
        "\n",
        "def normalize_and_tokenize(text: str, base_tokenization_func=None, normalize: bool = True) -> List[str]:\n",
        "    normalized_text = text\n",
        "    if normalize:\n",
        "        normalized_text = \" \".join(bpe_tokenizer.tokenize(normalized_text))\n",
        "    tokens = [normalized_text]\n",
        "    if base_tokenization_func is not None:\n",
        "        tokens = base_tokenization_func(normalized_text)\n",
        "    return tokens\n",
        "\n",
        "\n",
        "def get_possible_token_list(token_list: List[str], new_tokenization_func=None) -> List[str]:\n",
        "    filtered_token_list = token_list\n",
        "    if new_tokenization_func is not None:\n",
        "        filtered_token_list = []\n",
        "        for i in token_list:\n",
        "            filtered_token_list.extend(new_tokenization_func(i))\n",
        "    return filtered_token_list\n",
        "\n",
        "\n",
        "def convert_df_dict_to_tokenizer(idf_dict: Dict[str, int], new_token_list: List[str], tokenization_func):\n",
        "    converted_df_dict = defaultdict(lambda: 0, ((k, 0) for k in new_token_list))\n",
        "    # total_tokens = len(new_token_list)\n",
        "\n",
        "    for token, idf_freq in idf_dict.items():\n",
        "        tokenized = tokenization_func(token)\n",
        "        # num_subtokens = len(tokenized) if isinstance(tokenized, list) else 1\n",
        "        # token_freq = idf_freq / num_subtokens\n",
        "        token_freq = idf_freq\n",
        "\n",
        "        # Распределение частоты по токенам\n",
        "        for subtoken in tokenized:\n",
        "            # converted_df_dict[subtoken] += token_freq / total_tokens\n",
        "            converted_df_dict[subtoken] += token_freq\n",
        "\n",
        "    return converted_df_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "33242e68-0f04-4a76-a4ae-f9c23267e3aa",
      "metadata": {
        "tags": [],
        "id": "33242e68-0f04-4a76-a4ae-f9c23267e3aa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00cfb815-252f-4156-c6c3-9f7ad0798725"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Possible tokens count: 158768\n",
            "Reduced the size of DF dict by 90.62%\n"
          ]
        }
      ],
      "source": [
        "from functools import partial\n",
        "\n",
        "\n",
        "better_tokenizer = partial(normalize_and_tokenize,\n",
        "                           base_tokenization_func=bpe_tokenizer.tokenize)\n",
        "\n",
        "# Исходные токены словаря могут быть в нечитаемом/искаженном виде, поэтому нужно сначала привести их в естественную форму\n",
        "new_tokens = [bpe_tokenizer.convert_tokens_to_string([token]) for token in\n",
        "              bpe_tokenizer.get_vocab().keys() if token not in bpe_tokenizer.all_special_tokens]\n",
        "\n",
        "possible_tokens = get_possible_token_list(new_tokens, better_tokenizer)\n",
        "print(\"Possible tokens count:\", len(possible_tokens))\n",
        "\n",
        "new_df_dict = convert_df_dict_to_tokenizer(\n",
        "    raw_word_df, possible_tokens, better_tokenizer)\n",
        "\n",
        "print(\"Reduced the size of DF dict by {:.2%}\".format(\n",
        "    1 - len(new_df_dict)/len(raw_word_df)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eb91fa67-ccff-4096-9828-c9ecd6fb06e1",
      "metadata": {
        "scrolled": true,
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eb91fa67-ccff-4096-9828-c9ecd6fb06e1",
        "outputId": "0948f28c-1859-487f-f03e-a1ebda4eb870"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Вектор:\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            "Плотность:\n",
            " 0.00143%\n",
            "Ненулевые значения:\n",
            " [-1.50902807e-05  0.00000000e+00  3.96866489e+00  4.30715952e+00\n",
            "  4.40226002e+00  4.44957229e+00  4.59818154e+00  4.61776569e+00\n",
            "  4.82558139e+00  4.89988962e+00  4.97038479e+00  5.05052020e+00\n",
            "  5.05169872e+00  5.07362948e+00  5.24100471e+00  5.28106618e+00\n",
            "  5.30947460e+00  5.39172587e+00  5.41345993e+00  5.42578156e+00\n",
            "  5.43866063e+00  5.45790454e+00  5.47220856e+00  5.48765272e+00\n",
            "  5.50943185e+00  5.55469366e+00  5.60248211e+00  5.66120874e+00\n",
            "  5.68851663e+00  5.69893936e+00  5.70550917e+00  5.74888531e+00\n",
            "  5.75114570e+00  5.76874080e+00  5.83414102e+00  5.85811425e+00\n",
            "  5.87991027e+00  5.89611213e+00  5.90180687e+00  6.01702646e+00\n",
            "  6.05018837e+00  6.17986734e+00  6.20145276e+00  6.22130388e+00\n",
            "  6.26020668e+00  6.27454218e+00  6.28795262e+00  6.33343914e+00\n",
            "  6.35208840e+00  6.38441527e+00  6.41749972e+00  6.42040561e+00\n",
            "  6.46781737e+00  6.49466283e+00  6.54014410e+00  6.69289860e+00\n",
            "  6.73747261e+00  6.85629215e+00  6.91356821e+00  7.03064553e+00\n",
            "  7.04161821e+00  7.13909724e+00  7.15312709e+00  7.17031819e+00\n",
            "  7.21130181e+00  7.21320521e+00  7.24391734e+00  7.28938542e+00\n",
            "  7.32414220e+00  7.33701974e+00  7.34867773e+00  7.35140848e+00\n",
            "  7.35332445e+00  7.38166755e+00  7.41054733e+00  7.45655633e+00\n",
            "  7.45929398e+00  7.46265020e+00  7.46479185e+00  7.47464112e+00\n",
            "  7.47525993e+00  7.54412016e+00  7.55311273e+00  7.57202582e+00\n",
            "  7.61202420e+00  7.61771817e+00  7.67236054e+00  7.71983231e+00\n",
            "  7.75933765e+00  7.77258288e+00  7.80648443e+00  7.82387617e+00\n",
            "  7.86552087e+00  7.88491206e+00  7.91040919e+00  7.91376249e+00\n",
            "  7.95540456e+00  7.96192905e+00  7.96951059e+00  7.97103382e+00\n",
            "  8.04866581e+00  8.06137668e+00  8.07425119e+00  8.08957934e+00\n",
            "  8.09244385e+00  8.10340444e+00  8.10805561e+00  8.12154951e+00\n",
            "  8.14364656e+00  8.15031123e+00  8.15453171e+00  8.16995582e+00\n",
            "  8.18306053e+00  8.21367516e+00  8.22409192e+00  8.24058850e+00\n",
            "  8.25465909e+00  8.32018775e+00  8.34130248e+00  8.37497569e+00\n",
            "  8.39131944e+00  8.39340940e+00  8.41218929e+00  8.41377032e+00\n",
            "  8.41852846e+00  8.42359449e+00  8.44643392e+00  8.45577973e+00\n",
            "  8.46839866e+00  8.51003032e+00  8.51439523e+00  8.51702335e+00\n",
            "  8.52318263e+00  8.58132798e+00  8.58507682e+00  8.60499213e+00\n",
            "  8.61752241e+00  8.65911256e+00  8.68471560e+00  8.71633046e+00\n",
            "  8.72493266e+00  8.73034686e+00  8.75008434e+00  8.75341213e+00\n",
            "  8.76908994e+00  8.82002688e+00  8.83247518e+00  8.83921212e+00\n",
            "  8.86124484e+00  8.87369830e+00  9.00615615e+00  9.01045723e+00\n",
            "  9.02347260e+00  9.03371410e+00  9.05451977e+00  9.05601985e+00\n",
            "  9.06369544e+00  9.07045766e+00  9.08966217e+00  9.11167564e+00\n",
            "  9.12126038e+00  9.14234794e+00  9.14892691e+00  9.15223270e+00\n",
            "  9.17399088e+00  9.18590591e+00  9.19277879e+00  9.25502110e+00\n",
            "  9.27354015e+00  9.28104487e+00  9.31358363e+00  9.31943730e+00\n",
            "  9.33323063e+00  9.35529772e+00  9.36344440e+00  9.36959827e+00\n",
            "  9.37372199e+00  9.37993962e+00  9.38410630e+00  9.38829040e+00\n",
            "  9.40094880e+00  9.42240885e+00  9.46223712e+00  9.46449701e+00\n",
            "  9.50136755e+00  9.50371772e+00  9.51080158e+00  9.53478354e+00\n",
            "  9.55687033e+00  9.56184547e+00  9.56434235e+00  9.57692113e+00\n",
            "  9.58199728e+00  9.60777190e+00  9.62621775e+00  9.65317356e+00\n",
            "  9.66692894e+00  9.70648211e+00  9.71226248e+00  9.71516524e+00\n",
            "  9.76584672e+00  9.84207409e+00  9.86883154e+00  9.88938021e+00\n",
            "  9.89284641e+00  9.93178939e+00  9.93540603e+00  9.94633510e+00\n",
            "  9.95000483e+00  9.99512526e+00  9.99897883e+00  1.00106294e+01\n",
            "  1.00383540e+01  1.00545487e+01  1.00586387e+01  1.00668692e+01\n",
            "  1.01264613e+01  1.01352719e+01  1.01805285e+01  1.01851689e+01\n",
            "  1.02086994e+01  1.02931167e+01  1.03628500e+01  1.03684211e+01\n",
            "  1.03910209e+01  1.04025153e+01  1.04318429e+01  1.04744025e+01\n",
            "  1.04995611e+01  1.05385271e+01  1.06141645e+01  1.06353404e+01\n",
            "  1.06358260e+01  1.06806096e+01  1.06959945e+01  1.07116198e+01\n",
            "  1.07195250e+01  1.07274932e+01  1.07517858e+01  1.07766834e+01\n",
            "  1.07851223e+01  1.08108748e+01  1.08196084e+01  1.08462767e+01\n",
            "  1.08644590e+01  1.08923678e+01  1.09018465e+01  1.09406864e+01\n",
            "  1.09506367e+01  1.09708394e+01  1.11131556e+01  1.11369663e+01\n",
            "  1.11490876e+01  1.11613577e+01  1.11990981e+01  1.12120015e+01\n",
            "  1.12250736e+01  1.12381560e+01  1.12383188e+01  1.12517418e+01\n",
            "  1.12791408e+01  1.13217004e+01  1.13661522e+01  1.13814196e+01\n",
            "  1.13942150e+01  1.14286725e+01  1.14614623e+01  1.14953639e+01\n",
            "  1.15648022e+01  1.15668228e+01  1.15855150e+01  1.16639866e+01\n",
            "  1.16746490e+01  1.17056593e+01  1.17271655e+01  1.17946068e+01\n",
            "  1.18453711e+01  1.18669274e+01  1.18922452e+01  1.20169888e+01\n",
            "  1.20294464e+01  1.20900710e+01  1.21885111e+01  1.21981506e+01\n",
            "  1.22086518e+01  1.22599700e+01  1.22814627e+01  1.22977104e+01\n",
            "  1.23369311e+01  1.26113679e+01  1.27996342e+01  1.29770578e+01\n",
            "  1.30709002e+01  1.31002305e+01  1.31973655e+01  1.33585823e+01\n",
            "  1.35283529e+01  1.36599497e+01  1.38534292e+01  1.39590722e+01\n",
            "  1.41657263e+01  1.42653285e+01  1.44893087e+01  1.51639250e+01\n",
            "  1.54114067e+01  1.55558069e+01  1.56026507e+01  1.59820998e+01\n",
            "  1.60018967e+01  1.77604003e+01  1.79839027e+01  1.80674282e+01\n",
            "  1.80792276e+01  1.82457336e+01  1.93229602e+01  2.00924077e+01\n",
            "  2.10476916e+01  2.13159342e+01  2.15702445e+01  2.17238389e+01\n",
            "  2.21119944e+01  2.21797976e+01  2.22263113e+01  2.25188865e+01\n",
            "  2.32091264e+01  2.40009177e+01  2.40768086e+01  2.41148581e+01\n",
            "  2.44182852e+01  2.50572041e+01  2.65505034e+01  3.09224133e+01\n",
            "  3.14166181e+01  3.15658410e+01  3.24066501e+01  3.31679917e+01\n",
            "  3.39219350e+01  3.51169779e+01  3.53148518e+01  3.55267045e+01\n",
            "  4.41659675e+01  4.83966140e+01  4.95930841e+01  5.12997278e+01\n",
            "  6.68945259e+01  8.17891781e+01]\n"
          ]
        }
      ],
      "source": [
        "better_vectorizer = TfIdfVectorizer(\n",
        "    df_dict=new_df_dict, tokenizer=better_tokenizer)\n",
        "\n",
        "test_vector = better_vectorizer(document_text)\n",
        "print(\"Вектор:\\n\", test_vector)\n",
        "print(\"Плотность:\\n {:.5%}\".format(\n",
        "    len(test_vector.nonzero())/test_vector.shape[-1]))\n",
        "print(\"Ненулевые значения:\\n\", np.unique(test_vector))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e4ce6715-5ff7-430c-b3e4-b9c1cc9d676d",
      "metadata": {
        "id": "e4ce6715-5ff7-430c-b3e4-b9c1cc9d676d"
      },
      "source": [
        "### Задание 2.4: написать алгоритм MMR\n",
        "\n",
        "Один из первых подходов к отбору важной текстовой информации - алгоритм ранжирования по cходству с запросом **MMR**.\n",
        "\n",
        "Суть алгоритма - последовательный отбор фрагментов текста, таких что:\n",
        "* добавляемый фрагмент $s_i \\in DOC$ наиболее близок к запросу $Query$\n",
        "* добавляемый фрагмент $s_i \\in DOC$ наиболее отдален от ранее отобранных фрагментов $s_j \\in S_{k-1}$\n",
        "\n",
        "Формально решается задача оптимизации:\n",
        "$$S_k = S_{k-1} \\cup \\arg{\\max}_{s_i \\in DOC \\setminus S_{k-1}} \\text{MMR}(s_i,S_{k-1}, Query)$$\n",
        "$$\\text{MMR}(s_i,S_{k-1}, Query)=-\\delta \\cdot \\text{similarity}(s_i, S_{k-1}) + (1-\\delta) \\cdot \\text{similarity}(s_i, Query)$$\n",
        "\n",
        "Под сходством/близостью подразумевается *косинусное сходство* (нормированное евклидовое расстояние):\n",
        "$$\\text{similarity}(a, b) = \\text{cosine-similarity}(\\text{Embedding}(a), \\text{Embedding}(b))$$\n",
        "\n",
        "При **$Query=DOC$** алгоритм сводится к ранжированию предложений по центральности без тематических повторов, то есть **экстрактивному аннотированию**.\n",
        "\n",
        "Используя формулы выше допишите функцию рассчета MMR\n",
        "\n",
        "*Полезно:* np.max, np.argmax"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7506f40b-59de-4452-9488-30f47617b637",
      "metadata": {
        "id": "7506f40b-59de-4452-9488-30f47617b637"
      },
      "outputs": [],
      "source": [
        "def l2_norm(a):\n",
        "    return np.nan_to_num(a/np.linalg.norm(a, axis=-1, keepdims=True))\n",
        "\n",
        "\n",
        "def cosine_similarity(a, b):\n",
        "    a = l2_norm(a)\n",
        "    b = l2_norm(b)\n",
        "    return a@b.T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c0ee3ffd-3285-4cba-b2b8-2de6de1fb02a",
      "metadata": {
        "id": "c0ee3ffd-3285-4cba-b2b8-2de6de1fb02a"
      },
      "outputs": [],
      "source": [
        "def MMR(sentence_embeddings: np.ndarray, query_embedding: np.ndarray = None, delta: float = 0.2, topk: int = None):\n",
        "    ranking = []\n",
        "    if topk is None:\n",
        "        topk = sentence_embeddings.shape[0]\n",
        "    topk = min(topk, sentence_embeddings.shape[0])\n",
        "\n",
        "    # Центральная тематика документа/кластера предложений\n",
        "    if query_embedding is None:\n",
        "        query_embedding = np.mean(sentence_embeddings, axis=0)  # исправил sent_embs на sentence_embeddings\n",
        "\n",
        "    selected_indices = []  # список индексов уже выбранных предложений\n",
        "    while len(ranking) < topk:\n",
        "        remaining_indices = [i for i in range(sentence_embeddings.shape[0]) if i not in selected_indices]\n",
        "        if not remaining_indices:\n",
        "            break  # прерываем, если все предложения уже выбраны\n",
        "\n",
        "        # Вычисляем MMR для каждого оставшегося предложения\n",
        "        MMR_values = []\n",
        "        for i in remaining_indices:\n",
        "            # близость к запросу\n",
        "            sim_to_query = cosine_similarity(sentence_embeddings[i:i+1], query_embedding[np.newaxis])[0, 0]\n",
        "            # близость к уже выбранным предложениям\n",
        "            if selected_indices:\n",
        "                sim_to_selected = cosine_similarity(sentence_embeddings[i:i+1], sentence_embeddings[selected_indices]).max()\n",
        "            else:\n",
        "                sim_to_selected = 0\n",
        "            MMR_value = (1 - delta) * sim_to_query - delta * sim_to_selected\n",
        "            MMR_values.append(MMR_value)\n",
        "\n",
        "        # выбираем предложение с максимальным значением MMR\n",
        "        best_idx_in_remaining = np.argmax(MMR_values)\n",
        "        best_idx = remaining_indices[best_idx_in_remaining]\n",
        "\n",
        "        # добавляем лучшее предложение в ranking и обновляем selected_indices\n",
        "        ranking.append(best_idx)\n",
        "        selected_indices.append(best_idx)\n",
        "\n",
        "    return ranking[:topk]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a9478d18-a360-43a4-8921-a0f1b41249f4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a9478d18-a360-43a4-8921-a0f1b41249f4",
        "outputId": "f423db6c-6c36-4d25-efa7-ee8cd097aa8f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "***ТЕКСТ ПРЕДСКАЗАННОЙ АННОТАЦИИ:***\n",
            "\n",
            "В Туве, Ингушетии и Кабардино-Балкарии по итогам 2020 года зафиксирован наибольший уровень бедности населения.\n",
            "Меньше всего доля бедного населения (от 5% до 10%) в Москве, Санкт-Петербурге, Подмосковье, Калужской, Ленинградской, Нижегородской, Курской, Белгородской, Воронежской, Свердловской, Ярославской, Магаданской и Сахалинской областях, Татарстане, Ямало-Ненецком, Ханты-Мансийском и Чукотском автономном округах.\n",
            "Лебедев заявил, что наибольшей проблемой в борьбе с низкими доходами населения является так называемая якорная бедность.\n",
            "Согласно данным Росстата на 6 августа, в стране насчитывалось 17,7 млн человек, живущих за чертой бедности — это 12,1% от населения.\n",
            "В десятку субъектов с наибольшей долей бедного населения также входили Республика Алтай, Еврейская автономная область, Калмыкия, Карачаево-Черкессия, Забайкалье, Чечня и Марий Эл.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "example = data['train'][example_id]\n",
        "sent_embs = np.stack([better_vectorizer(sent) for sent in example['document']])\n",
        "\n",
        "delta = 0.3\n",
        "extractive_prediction = MMR(\n",
        "    sentence_embeddings=sent_embs, delta=delta, topk=5)\n",
        "\n",
        "# Нужно для связности аннотации\n",
        "extractive_prediction = sorted(extractive_prediction)\n",
        "\n",
        "summary = \"\\n\".join(example['document'][sent_id]\n",
        "                   for sent_id in extractive_prediction)\n",
        "print(\"***ТЕКСТ ПРЕДСКАЗАННОЙ АННОТАЦИИ:***\", f\"{summary}\\n\", sep='\\n\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c8229267-ff4b-495b-862a-97a1b0daada4",
      "metadata": {
        "id": "c8229267-ff4b-495b-862a-97a1b0daada4"
      },
      "source": [
        "## Часть 3: LexRank (a.k.a. TextRank с фильтрацией ребер)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "51c0f65b-809c-4d88-bd51-989a29508a58",
      "metadata": {
        "id": "51c0f65b-809c-4d88-bd51-989a29508a58"
      },
      "source": [
        "Когда говорят об экстрактивной суммаризации часто подразумевают семейство алгоритмов ранжирования по центральности PageRank. В частности применяют **LexRank**, который часто в медиа называют TextRank, хотя TextRank является частным случаем LexRank.\n",
        "\n",
        "Идея заключается в представлении текста в виде графа, в котором вершины - конкретные фрагменты (например, предложения), а ребра - мера сходства двух фрагментов. Тогда, пользуясь фактом, что возведение матрицы смежности $A$ в степень $m$ дает матрицу суммы весов всевозможных путей длины $m$ (в т.ч. пути с петлями), мы можем оценить важность (центральность) предложения $s_i$ как значение $\\sum_j{A^m_{ij}}$.\n",
        "\n",
        "Формально вектор оценки центральностей предложений текста $p_k$ вычисляется следующим образом:\n",
        "$$p^k=A \\cdot p^{k-1}$$\n",
        "$$A=[d\\cdot b + (1-d)\\cdot M]$$\n",
        "$$M_{ij} = \\text{similarity}(s_i,s_j)$$\n",
        "$$s_i \\in \\text{Sentences}(DOC)$$\n",
        "$$p^0_{ij} = 1$$\n",
        "где $d$ - коэффициент девиации, $b$ - вектор девиации, $A$ - матрица смежности графа предложений текста.\n",
        "\n",
        "В простейшем случае вектор $b$ равен равномерному распределению (то есть можем перейти в любую вершину):\n",
        "$$b_{ij}=\\frac{1}{|\\text{Sentences}(DOC)|}$$\n",
        "Однако этот же вектор можно использовать для увеличения веса \"важности\" конкретных предложений.\n",
        "\n",
        "**$p_k$ вычисляется до тех пор, пока изменения значимы**:\n",
        "$$||p_k-p_{k-1}||_2\\geq \\varepsilon$$\n",
        "\n",
        "**Алгоритм LexRank сходится тогда и только тогда, когда**:\n",
        "$$\\sum_{1\\leq i \\leq |\\text{Sentences}(DOC)|} {A_{ij}}=1,\\quad\\quad \\forall 1\\leq j \\leq |\\text{Sentences}(DOC)|$$\n",
        "То есть когда матрица смежности $A$ стохастическая"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fec889c5-fc3c-4d3a-8beb-f9e47a761084",
      "metadata": {
        "id": "fec889c5-fc3c-4d3a-8beb-f9e47a761084"
      },
      "outputs": [],
      "source": [
        "def sum_norm(a, axis=0):\n",
        "    return np.nan_to_num(a/a.sum(axis=axis, keepdims=True))\n",
        "\n",
        "\n",
        "def GetTransitionMatrix(sentence_embeddings: np.ndarray, bias_vector: np.ndarray = None, damping_coef: float = 0.1, edge_threshold=0):\n",
        "    A=np.array(0)\n",
        "    \"\"\" ДОПИШИТЕ СЮДА НЕОБХОДИМЫЙ КОД \"\"\"\n",
        "    return A\n",
        "\n",
        "\n",
        "def LexRank(sentence_embeddings: np.ndarray, bias_vector: np.ndarray = None, damping_coef: float = 0.1, topk: int = None, epsilon=1e-5, edge_threshold=0):\n",
        "    p = np.ones(sentence_embeddings.shape[0])\n",
        "    if bias_vector is None:\n",
        "        bias_vector = np.ones(\n",
        "            (sentence_embeddings.shape[0], 1))/sentence_embeddings.shape[0]\n",
        "\n",
        "    assert bias_vector.shape == (\n",
        "        sentence_embeddings.shape[0], 1), f\"bias_vector must be of shape {(sentence_embeddings.shape[0], 1)}\"\n",
        "\n",
        "    assert edge_threshold <= 1, \"edge_threshold must be in range [0,1]\"\n",
        "\n",
        "    A = GetTransitionMatrix(sentence_embeddings, bias_vector)\n",
        "\n",
        "    assert np.allclose(\n",
        "        A.sum(axis=0), 1), \"Transition matrix must be stochastic\"\n",
        "\n",
        "    \"\"\" ДОПИШИТЕ СЮДА фильтрацию ребер по edge_threshold\"\"\"\n",
        "\n",
        "    # Main loop\n",
        "    p_prev = 0\n",
        "    while not np.allclose(p, p_prev, atol=epsilon):\n",
        "        p_prev = p\n",
        "        p = A @ p\n",
        "        # fast power trick\n",
        "        A = A @ A\n",
        "\n",
        "    ranking = list(zip(*sorted(enumerate(p), key=lambda x: -x[1])))[0][:topk]\n",
        "    return ranking"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "025c4feb-7c58-4270-b951-27ffb8270caa",
      "metadata": {
        "scrolled": true,
        "tags": [],
        "id": "025c4feb-7c58-4270-b951-27ffb8270caa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "outputId": "3dd72a7a-4309-4599-affb-1c0d42c6a6f2"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-a1ea3066ce35>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mbias_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msent_embs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mbias_vector\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbias_idx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m assert LexRank(sentence_embeddings=sent_embs, bias_vector=bias_vector,\n\u001b[0m\u001b[1;32m     10\u001b[0m                damping_coef=delta, topk=5)[0] == bias_idx\n",
            "\u001b[0;32m<ipython-input-34-5498dcadfbd3>\u001b[0m in \u001b[0;36mLexRank\u001b[0;34m(sentence_embeddings, bias_vector, damping_coef, topk, epsilon, edge_threshold)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGetTransitionMatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence_embeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias_vector\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     assert np.allclose(\n\u001b[0m\u001b[1;32m     25\u001b[0m         A.sum(axis=0), 1), \"Transition matrix must be stochastic\"\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAssertionError\u001b[0m: Transition matrix must be stochastic"
          ]
        }
      ],
      "source": [
        "example = data['train'][example_id]\n",
        "sent_embs = np.stack([better_vectorizer(sent) for sent in example['document']])\n",
        "\n",
        "# Test sentence biasing\n",
        "delta = 1\n",
        "bias_vector = np.zeros((sent_embs.shape[0], 1))\n",
        "bias_idx = np.random.randint(0, sent_embs.shape[0], 1)[0]\n",
        "bias_vector[bias_idx] = 1\n",
        "assert LexRank(sentence_embeddings=sent_embs, bias_vector=bias_vector,\n",
        "               damping_coef=delta, topk=5)[0] == bias_idx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "abf07d23-887d-4b07-b949-6ec66e42705e",
      "metadata": {
        "scrolled": true,
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 366
        },
        "id": "abf07d23-887d-4b07-b949-6ec66e42705e",
        "outputId": "46f97681-d8bf-4c0d-ded3-775d60e868cd"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-41078b5f674e>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mbias_vector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m33\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msent_embs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m extractive_prediction = LexRank(sentence_embeddings=sent_embs,\n\u001b[0m\u001b[1;32m      9\u001b[0m                                 bias_vector=bias_vector, damping_coef=delta, topk=topk, edge_threshold=threshold)\n\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextractive_prediction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-34-5498dcadfbd3>\u001b[0m in \u001b[0;36mLexRank\u001b[0;34m(sentence_embeddings, bias_vector, damping_coef, topk, epsilon, edge_threshold)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGetTransitionMatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence_embeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias_vector\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     assert np.allclose(\n\u001b[0m\u001b[1;32m     25\u001b[0m         A.sum(axis=0), 1), \"Transition matrix must be stochastic\"\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAssertionError\u001b[0m: Transition matrix must be stochastic"
          ]
        }
      ],
      "source": [
        "# Тут можно играть с параметрами\n",
        "delta = 0.1\n",
        "topk = 4\n",
        "threshold = 0\n",
        "# Этот вектор можно заменить на None\n",
        "bias_vector = np.random.randint(0, 33, sent_embs.shape[0]).reshape((-1, 1))\n",
        "\n",
        "extractive_prediction = LexRank(sentence_embeddings=sent_embs,\n",
        "                                bias_vector=bias_vector, damping_coef=delta, topk=topk, edge_threshold=threshold)\n",
        "print(extractive_prediction)\n",
        "\n",
        "# Нужно для связности аннотации\n",
        "extractive_prediction = sorted(extractive_prediction)\n",
        "\n",
        "summary = \" \".join(example['document'][sent_id]\n",
        "                   for sent_id in extractive_prediction)\n",
        "print(\"***ТЕКСТ ПРЕДСКАЗАННОЙ АННОТАЦИИ:***\", f\"{summary}\\n\", sep='\\n\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "479a198f-b8d5-468b-9d92-dcf00ba0929e",
      "metadata": {
        "id": "479a198f-b8d5-468b-9d92-dcf00ba0929e"
      },
      "source": [
        "## Часть 4: Cluster Titles"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9fe6ea61-a788-4904-98d0-ae0a3b7d98ef",
      "metadata": {
        "id": "9fe6ea61-a788-4904-98d0-ae0a3b7d98ef"
      },
      "source": [
        "Интересный метод на основе тематической кластеризации - **Cluster Titles**. Метод известен благодаря библиотеке *bert-extractive-summarizer* и часто можно встретить на форумах.\n",
        "\n",
        "Смысл метода заключается в все том же построении матрицы сходства, но теперь она разбивается на клики или, если их изолировать, кластеры. Каждая клика/кластер рассматривается как отдельная компонента связности к которой применяется метод экстрактивной суммаризации с выбором Top-1 предложения по мере важности (центральности). Аннотация для документа получается путем склейки всех Top-1 предложений кластеров."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e9756d90-c663-45e9-9c48-344689b9a86b",
      "metadata": {
        "id": "e9756d90-c663-45e9-9c48-344689b9a86b"
      },
      "outputs": [],
      "source": [
        "from sklearn.cluster import KMeans, Birch, DBSCAN\n",
        "\n",
        "\n",
        "def ClusterTitles(sentence_embeddings: np.ndarray, cluster_algorithm=None, **kwargs):\n",
        "    titles = []\n",
        "    assert hasattr(cluster_algorithm, \"fit\"), \"Function designed for sklearn\"\n",
        "    \"\"\" ДОПИШИТЕ СЮДА НЕОБХОДИМЫЙ КОД \"\"\"\n",
        "    return titles"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9008ccb3-bfdf-4bda-add2-49aa72b9094c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "9008ccb3-bfdf-4bda-add2-49aa72b9094c",
        "outputId": "383ec4d6-eb11-4246-ad91-9447852bffa9"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-40-7b7bbed6238e>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Tests\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mClusterTitles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent_embs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcluster_algorithm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mKMeans\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m>=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mtmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mClusterTitles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent_embs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcluster_algorithm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mKMeans\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_clusters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m>=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAssertionError\u001b[0m: "
          ]
        }
      ],
      "source": [
        "example = data['train'][example_id]\n",
        "sent_embs = np.stack([better_vectorizer(sent) for sent in example['document']])\n",
        "\n",
        "# Tests\n",
        "tmp = ClusterTitles(sent_embs, cluster_algorithm=KMeans())\n",
        "assert len(tmp) == len(set(tmp)) and len(tmp) >= 1\n",
        "tmp = ClusterTitles(sent_embs[:1], cluster_algorithm=KMeans(n_clusters=1))\n",
        "assert len(tmp) == len(set(tmp)) and len(tmp) >= 1\n",
        "tmp = ClusterTitles(sent_embs, cluster_algorithm=DBSCAN())\n",
        "assert len(tmp) == len(set(tmp)) and len(tmp) >= 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1ee437cd-76f0-40ee-a392-eb8355b7c13a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ee437cd-76f0-40ee-a392-eb8355b7c13a",
        "outputId": "99612c81-4864-4816-f1ae-04a19e040b50"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[]\n",
            "***ТЕКСТ ПРЕДСКАЗАННОЙ АННОТАЦИИ:***\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "sent_embs = np.stack([better_vectorizer(sent) for sent in example['document']])\n",
        "\n",
        "cluster_alg = KMeans(n_clusters=3)\n",
        "\n",
        "extractive_prediction = ClusterTitles(sent_embs, cluster_alg)\n",
        "print(extractive_prediction)\n",
        "\n",
        "# Нужно для связности аннотации\n",
        "extractive_prediction = sorted(extractive_prediction)\n",
        "\n",
        "summary = \" \".join(example['document'][sent_id]\n",
        "                   for sent_id in extractive_prediction)\n",
        "print(\"***ТЕКСТ ПРЕДСКАЗАННОЙ АННОТАЦИИ:***\", f\"{summary}\\n\", sep='\\n\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "15e6c803-fb09-4018-9bc1-9b3dc7e88c08",
      "metadata": {
        "id": "15e6c803-fb09-4018-9bc1-9b3dc7e88c08"
      },
      "source": [
        "## Часть 5: LSA"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fa357cc9-6ec7-48a3-9fc5-4dd912666282",
      "metadata": {
        "id": "fa357cc9-6ec7-48a3-9fc5-4dd912666282"
      },
      "source": [
        "Основным принципом тематического моделирования является гипотеза, что текст и его содержимое зависит только от выбранной темы, а сама вероятность выбора темы зависит статистики предметной области.\n",
        "\n",
        "Метод Latent Semantic Analysis - это попытка выявить основные темы текста. Основаная идея заключается в разложении семантической матрицы предложений документа $M\\in \\mathbb{R}^{n \\times m}$ на сингулярные матрицы порядка $k$:\n",
        "$$M=U\\Sigma V^T$$\n",
        "Где:\n",
        "* $\\Sigma\\in \\mathbb{R}^{k \\times k}$ - матрица $k$ скрытых тематик текста, на диагонали которой находятся коэффициент влияния тематики\n",
        "* $U\\in \\mathbb{R}^{n \\times k}$ - матрица выраженности тематик в компонентах предложений (для TF-IDF это слова словаря)\n",
        "* $V\\in \\mathbb{R}^{m \\times k}$ - матрица выраженности тематик в самих предложениях текста\n",
        "\n",
        "Наиболее важные предложения как правило раскрывают самые важные тематики, отсюда и формула оценки важности предложений:\n",
        "$$\\textbf{SCORE}(s_i\\in \\text{Sentences}(Doc))=\\sqrt{(diag(\\Sigma)V)^2}$$\n",
        "\n",
        "Напишите реализацию алгоритма используя готовые функции разложения библиотеки *Scipy*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6a086734-c0f5-4ad5-a558-fc9b872f53e7",
      "metadata": {
        "id": "6a086734-c0f5-4ad5-a558-fc9b872f53e7"
      },
      "outputs": [],
      "source": [
        "from scipy.sparse.linalg import svds\n",
        "\n",
        "\n",
        "def lsa_summarization(sentence_embeddings: np.ndarray, topk=5, number_of_topics=5, filter_threshold_pct=0.5):\n",
        "    ranking = []\n",
        "    \"\"\" ДОПИШИТЕ СЮДА НЕОБХОДИМЫЙ КОД ИСПОЛЬЗУЯ ФУНКЦИЮ svds\"\"\"\n",
        "    return ranking[:topk]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b8ec54aa-b39c-4072-9f72-a9a677e2524e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b8ec54aa-b39c-4072-9f72-a9a677e2524e",
        "outputId": "9314bf6e-caf0-42d8-9650-3e8927438cc6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[]\n",
            "***ТЕКСТ ПРЕДСКАЗАННОЙ АННОТАЦИИ:***\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "example = data['train'][example_id]\n",
        "sent_embs = np.stack([better_vectorizer(sent) for sent in example['document']])\n",
        "\n",
        "topk = 5\n",
        "num_topics = 3\n",
        "\n",
        "extractive_prediction = lsa_summarization(\n",
        "    sent_embs, topk=topk, number_of_topics=num_topics)\n",
        "print(extractive_prediction)\n",
        "\n",
        "# Нужно для связности аннотации\n",
        "extractive_prediction = sorted(extractive_prediction)\n",
        "\n",
        "summary = \" \".join(example['document'][sent_id]\n",
        "                   for sent_id in extractive_prediction)\n",
        "print(\"***ТЕКСТ ПРЕДСКАЗАННОЙ АННОТАЦИИ:***\", f\"{summary}\\n\", sep='\\n\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3462ba36-9922-4ea3-9960-a8b64f1cf7ac",
      "metadata": {
        "id": "3462ba36-9922-4ea3-9960-a8b64f1cf7ac"
      },
      "source": [
        "## Часть 6: Оценка и сравнение"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "В качестве метрик мы будем рассматривать:\n",
        "* Метрику качества суммаризации\n",
        "$$\\text{ROUGE-}N_{F1}(a,b)=\\frac{2*\\text{ROUGE-}N_{prec}(a,b)*\\text{ROUGE-}N_{rec}(a,b)}{\\text{ROUGE-}N_{prec}(a,b)+\\text{ROUGE-}N_{rec}(a,b)}$$\\\n",
        "$$\\text{ROUGE-}N_{prec}(a,b)=\\frac{|\\text{N-grams}(a)\\cap \\text{N-grams}(b)|}{|\\text{N-grams}(a)|}$$\n",
        "$$\\text{ROUGE-}N_{rec}(a,b) = \\text{ROUGE-}N_{prec}(b,a)$$\n",
        "* Метрику точности классификации:\n",
        "$$\\text{Precision}(a,b)=\\frac{|a \\cap b|}{|a|}$$"
      ],
      "metadata": {
        "id": "5SUplFMknJU2"
      },
      "id": "5SUplFMknJU2"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "32ac73a8-17b5-466f-99ff-dde88f502def",
      "metadata": {
        "id": "32ac73a8-17b5-466f-99ff-dde88f502def"
      },
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "\n",
        "\n",
        "def rouge_n(prediction, reference, n=1):\n",
        "    scores = {\"prec\": 0, \"rec\": 0, \"f1\": 0}\n",
        "    \"\"\" ДОПИШИТЕ СЮДА НЕОБХОДИМЫЙ КОД \"\"\"\n",
        "    return scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b30315cc-4cb3-4a78-a259-c74a3652dc48",
      "metadata": {
        "id": "b30315cc-4cb3-4a78-a259-c74a3652dc48",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210
        },
        "outputId": "27b06d25-b63b-4b9b-aa22-0bd015ea86e6"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-50-74ea1b3c4aa9>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0mrouge_n\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"1 2 3 4\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"1 2\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'rec'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0mrouge_n\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"1 2\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"1 2 3 4\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'prec'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0mrouge_n\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"1 2\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"1 2\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'f1'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAssertionError\u001b[0m: "
          ]
        }
      ],
      "source": [
        "assert rouge_n(\"1 2 3 4\", \"1 2\")['rec'] == 1\n",
        "assert rouge_n(\"1 2\", \"1 2 3 4\")['prec'] == 1\n",
        "assert rouge_n(\"1 2\", \"1 2\")['f1'] == 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e5eba5ca-d5aa-4b52-a5b5-64ccd0771fc6",
      "metadata": {
        "id": "e5eba5ca-d5aa-4b52-a5b5-64ccd0771fc6"
      },
      "outputs": [],
      "source": [
        "def precision(predicted_labels, reference_labels):\n",
        "    score = 0\n",
        "    \"\"\" ДОПИШИТЕ СЮДА НЕОБХОДИМЫЙ КОД \"\"\"\n",
        "    return score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c47c0c1e-7a56-4b03-b507-f26ed30b017d",
      "metadata": {
        "id": "c47c0c1e-7a56-4b03-b507-f26ed30b017d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210
        },
        "outputId": "87563a0d-0f67-4af7-af5f-9bf47b05a990"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-53-ee19a272b32f>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0mprecision\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0mprecision\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0mprecision\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAssertionError\u001b[0m: "
          ]
        }
      ],
      "source": [
        "assert precision([0, 1, 2, 3], [0, 1]) == 0.5\n",
        "assert precision([0, 1], [0, 1]) == 1\n",
        "assert precision([], [0, 1]) == 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7f416c57-93be-489a-8e07-e4f4c7f9d92c",
      "metadata": {
        "id": "7f416c57-93be-489a-8e07-e4f4c7f9d92c"
      },
      "outputs": [],
      "source": [
        "def score_predictions(predictions,  references, predicted_labels, reference_labels):\n",
        "    scores = {\"R1\": [], \"R2\": [], \"Prec\": []}\n",
        "    for rouge in [1, 2]:\n",
        "        scores[f\"R{rouge}\"] = np.mean(\n",
        "            [rouge_n(p, r, rouge)[\"f1\"] for p, r in zip(predictions, references)])\n",
        "    scores[\"Prec\"] = np.mean([precision(p, r)\n",
        "                            for p, r in zip(predicted_labels, reference_labels)])\n",
        "    return scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "95df8a60-7799-48cb-9a96-fa320e3133de",
      "metadata": {
        "id": "95df8a60-7799-48cb-9a96-fa320e3133de"
      },
      "outputs": [],
      "source": [
        "from tqdm.auto import tqdm\n",
        "\n",
        "def predict_all(examples, method, vectorizer, topk=5):\n",
        "    all_preds=[]\n",
        "    for ex in tqdm(examples):\n",
        "        ground_truth_labels = ex['most_important_sentences']\n",
        "        reference = ex['cluster_summary']\n",
        "        source = ex['document']\n",
        "\n",
        "        sent_embs = np.stack([vectorizer(sent) for sent in source])\n",
        "\n",
        "        predicted_labels = sorted(method(sent_embs, topk=topk))\n",
        "        predicted_summary = \" \".join(source[sent_id]\n",
        "                                     for sent_id in predicted_labels)\n",
        "        all_preds.append((predicted_summary, reference, predicted_labels, ground_truth_labels))\n",
        "    return all_preds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4a8e9cf3-c369-4676-8e86-0f29f075a8a7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "a9951ceec72649efba7994b19c50a0f6",
            "6fd7374d340f461ea220811aa57a4d71",
            "31fe4a61e2b7410789a658783670d742",
            "215643a3c8184943b97857e2dc11152f",
            "d96fca452a0c48fb95f57b39900ee92d",
            "7511c9886f1644649a20f23437d23f25",
            "0cadb5083edc42a0a1fda9a786184650",
            "06351b53392b44b0b14f5b8299069376",
            "2260d210eea14e13a6a136ad7cfee88a",
            "125d28359672415db8a657ea8ef68d3a",
            "2005ca2f1a8f4a52a04f37fcf6607b9c"
          ]
        },
        "id": "4a8e9cf3-c369-4676-8e86-0f29f075a8a7",
        "outputId": "e55903ea-8f2e-4c8b-f507-569b48d7e10b"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/100 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a9951ceec72649efba7994b19c50a0f6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'R1': 0.0, 'R2': 0.0, 'Prec': 0.0}"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ],
      "source": [
        "from functools import partial\n",
        "import pandas as pd\n",
        "\n",
        "topk=5\n",
        "method=partial(ClusterTitles, cluster_algorithm=KMeans(n_clusters=topk, n_init='auto'))\n",
        "\n",
        "res=predict_all(data[\"test\"], lsa_summarization, better_vectorizer,topk=topk)\n",
        "score_predictions(*zip(*res))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "87ea2b96-0dd6-484c-afda-18e65a1a102a",
      "metadata": {
        "id": "87ea2b96-0dd6-484c-afda-18e65a1a102a"
      },
      "outputs": [],
      "source": [
        "\"\"\" ДОПИШИТЕ СЮДА КОД ОЦЕНКИ ВСЕХ МЕТОДОВ \"\"\""
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8iCuPsEFzxhd"
      },
      "id": "8iCuPsEFzxhd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "a2ea3c79-eb5c-4fff-8496-f118ecfe67bd",
      "metadata": {
        "id": "a2ea3c79-eb5c-4fff-8496-f118ecfe67bd"
      },
      "source": [
        "## Доп задание: улучшить результат посредством нейросетевых эмбеддингов"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f0fc09c6-435f-4e21-9bb9-2bff9ffba9fb",
      "metadata": {
        "id": "f0fc09c6-435f-4e21-9bb9-2bff9ffba9fb",
        "outputId": "f1d264e1-16ff-4c62-c41b-ad05dd6cc468"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No sentence-transformers model found with name ./models/rubert-tiny2/. Creating a new one with MEAN pooling.\n"
          ]
        }
      ],
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "neural_vectorizer = SentenceTransformer(ENCODER_MODEL_PATH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ee6597e8-eed3-4c98-935a-75f8ad3d5a10",
      "metadata": {
        "id": "ee6597e8-eed3-4c98-935a-75f8ad3d5a10",
        "outputId": "fd63cc36-a875-4b6f-8e2e-d18a6dd0cdef"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "' ДОПИШИТЕ СЮДА НЕОБХОДИМЫЙ КОД '"
            ]
          },
          "execution_count": 292,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\"\"\" ДОПИШИТЕ СЮДА НЕОБХОДИМЫЙ КОД \"\"\""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a9951ceec72649efba7994b19c50a0f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6fd7374d340f461ea220811aa57a4d71",
              "IPY_MODEL_31fe4a61e2b7410789a658783670d742",
              "IPY_MODEL_215643a3c8184943b97857e2dc11152f"
            ],
            "layout": "IPY_MODEL_d96fca452a0c48fb95f57b39900ee92d"
          }
        },
        "6fd7374d340f461ea220811aa57a4d71": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7511c9886f1644649a20f23437d23f25",
            "placeholder": "​",
            "style": "IPY_MODEL_0cadb5083edc42a0a1fda9a786184650",
            "value": "100%"
          }
        },
        "31fe4a61e2b7410789a658783670d742": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_06351b53392b44b0b14f5b8299069376",
            "max": 100,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2260d210eea14e13a6a136ad7cfee88a",
            "value": 100
          }
        },
        "215643a3c8184943b97857e2dc11152f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_125d28359672415db8a657ea8ef68d3a",
            "placeholder": "​",
            "style": "IPY_MODEL_2005ca2f1a8f4a52a04f37fcf6607b9c",
            "value": " 100/100 [00:01&lt;00:00, 71.06it/s]"
          }
        },
        "d96fca452a0c48fb95f57b39900ee92d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7511c9886f1644649a20f23437d23f25": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0cadb5083edc42a0a1fda9a786184650": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "06351b53392b44b0b14f5b8299069376": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2260d210eea14e13a6a136ad7cfee88a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "125d28359672415db8a657ea8ef68d3a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2005ca2f1a8f4a52a04f37fcf6607b9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}